# Complex-Wavelet-Inception-GAN-Audio-Synthesis
The adversarial audio synthesis started from the work of Chris Donahua et al.(https://github.com/chrisdonahue/wavegan), which aimed at the unsupervised audio synthesis. Following studies have used various strategies to improve the fidelity of generated audio, such as Phase Gradient Heap Integration introduced by Andr´es Maraﬁoti et al.(https://tifgan.github.io/#S-E), IF-Phase learning proposed by Jesse Engel et al.(https://github.com/tensorflow/magenta/tree/master/magenta/models/gansynth), inverse transform of Melspectrogram to raw wave audio (https://github.com/descriptinc/melgan-neurips), etc. Using different approaches, we explored in other ways for the adversarial generation of high-fidelity audio.
## Complex-valued convolutional neural network learns complex spectrogram
The learning representation of complex spectrogram can avoid scattering the information of phase. The complex spectrogram, however, can hardly be modeled by real-valued neural network. Introducing the DEEP COMPLEX NETWORKS (Chiheb Trabelsi et al.), we learned complex spectrogram directly to bypass the loss of phase while only learning the magnitude of spectrogram.
